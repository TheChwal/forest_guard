{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89cd9ea5",
   "metadata": {},
   "source": [
    "### Import and authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a16fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:06.609579Z",
     "start_time": "2021-05-26T13:24:05.192109Z"
    }
   },
   "outputs": [],
   "source": [
    "import ee \n",
    "import folium\n",
    "from datetime import datetime as dt\n",
    "from IPython.display import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98313e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:22.533190Z",
     "start_time": "2021-05-26T13:24:06.610883Z"
    }
   },
   "outputs": [],
   "source": [
    "ee.Initialize()\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58233a",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0fd25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:24.340184Z",
     "start_time": "2021-05-26T13:24:24.308647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "BUCKET = 'forest_guard_bucket'  # ⚠️ replace with your BUCKET NAME\n",
    "FOLDER = 'JP_data_forest_guards'\n",
    "TRAINING_BASE = 'training_patches'\n",
    "EVAL_BASE = 'eval_patches'\n",
    "\n",
    "OPTICAL_BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "THERMAL_BANDS = ['B10', 'B11']\n",
    "BANDS = OPTICAL_BANDS + THERMAL_BANDS\n",
    "RESPONSE = 'fnf'\n",
    "FEATURES = BANDS + [RESPONSE]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "# Specify model training parameters.\n",
    "BATCH_SIZE = 16\n",
    "# EPOCHS = 10\n",
    "BUFFER_SIZE = 2000\n",
    "# OPTIMIZER = 'SGD'\n",
    "# LOSS = 'MeanSquaredError'\n",
    "# METRICS = ['RootMeanSquaredError']\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd13c4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999afa03",
   "metadata": {},
   "source": [
    "#### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94df9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:27.668850Z",
     "start_time": "2021-05-26T13:24:26.784353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use Landsat 8 surface reflectance data.\n",
    "l8sr = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "\n",
    "# Cloud masking function from GEE\n",
    "def maskL8sr(image):\n",
    "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
    "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
    "  qa = image.select('pixel_qa')\n",
    "  mask1 = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
    "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "  mask2 = image.mask().reduce('min')\n",
    "  mask3 = image.select(OPTICAL_BANDS).gt(0).And(\n",
    "          image.select(OPTICAL_BANDS).lt(10000)).reduce('min')\n",
    "  mask = mask1.And(mask2).And(mask3)\n",
    "  return image.select(OPTICAL_BANDS).divide(10000).addBands(\n",
    "          image.select(THERMAL_BANDS).divide(10).clamp(273.15, 373.15)\n",
    "            .subtract(273.15).divide(100)).updateMask(mask)\n",
    "\n",
    "# The image input data is a cloud-masked median composite.\n",
    "image = l8sr.filterDate('2015-01-01', '2017-12-31').map(maskL8sr).median()\n",
    "\n",
    "# Use folium to visualize the imagery.\n",
    "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
    "map = folium.Map(location=[48.9, 2.5])\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='median composite',\n",
    "    opacity = 0.5\n",
    "  ).add_to(map)\n",
    "\n",
    "mapid = image.getMapId({'bands': ['B11'], 'min': 0, 'max': 0.5})\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='thermal',\n",
    "    opacity = 0.5\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16d927",
   "metadata": {},
   "source": [
    "#### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50f903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:29.100350Z",
     "start_time": "2021-05-26T13:24:28.709256Z"
    }
   },
   "outputs": [],
   "source": [
    "jaxa = ee.ImageCollection('JAXA/ALOS/PALSAR/YEARLY/FNF').filterDate('2017-01-01', '2017-12-31').median()\n",
    "\n",
    "jaxa_norm = jaxa.divide(100).float()\n",
    "\n",
    "palette = ['006400',\n",
    "           'FEFF99',\n",
    "         #  '0000FF'\n",
    "          ]\n",
    "mapid = jaxa.getMapId({'bands': ['fnf'],\n",
    "                       'min': 1, \n",
    "                       'max': 2, \n",
    "                      'palette':palette\n",
    "                      })\n",
    "map = folium.Map(location=[48.9, 2.5])\n",
    "\n",
    "\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='jaxa fnf',\n",
    "    color=palette,\n",
    "    opacity = 1\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f1fc4",
   "metadata": {},
   "source": [
    "### Stacking X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d4b3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:29.884120Z",
     "start_time": "2021-05-26T13:24:29.878224Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "featureStack = ee.Image.cat([\n",
    "  image.select(BANDS),\n",
    "  jaxa.select(RESPONSE)\n",
    "]).float()\n",
    "\n",
    "list = ee.List.repeat(1, KERNEL_SIZE)\n",
    "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
    "\n",
    "arrays = featureStack.neighborhoodToArray(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32d6a8",
   "metadata": {},
   "source": [
    "### Areas of interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff2c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:31.172582Z",
     "start_time": "2021-05-26T13:24:31.164854Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our own areas of interests\n",
    "# training features collection\n",
    "rect_train = ee.Geometry.Rectangle([3.327248985602229, 46.600827791084875, 4.689553673102229,47.70649093701327])\n",
    "trainingPolys = ee.FeatureCollection([rect_train])\n",
    "# eval features collections\n",
    "rect_eval = ee.Geometry.Rectangle([-0.7016469211726672,46.88962161312492, 0.9353159694523328,47.64998631126759])\n",
    "evalPolys= ee.FeatureCollection([rect_eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f037d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:32.084259Z",
     "start_time": "2021-05-26T13:24:31.939459Z"
    }
   },
   "outputs": [],
   "source": [
    "trainingPolys.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b8d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:32.891925Z",
     "start_time": "2021-05-26T13:24:32.554107Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "###   DEFINE OUR COLLECTSIONS OF AREAS OF INTEREST\n",
    "################################################\n",
    "# trainingPolys = ee.FeatureCollection('projects/google/DemoTrainingGeometries')\n",
    "# evalPolys = ee.FeatureCollection('projects/google/DemoEvalGeometries')\n",
    "\n",
    "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "map = folium.Map(location=[47., 0.], zoom_start=5)\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c541438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:34.012207Z",
     "start_time": "2021-05-26T13:24:34.006445Z"
    }
   },
   "outputs": [],
   "source": [
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7c1bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:35.731527Z",
     "start_time": "2021-05-26T13:24:35.725047Z"
    }
   },
   "outputs": [],
   "source": [
    "print(ee.Feature(trainingPolysList.get(0)).geometry())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fce18e",
   "metadata": {},
   "source": [
    "### Export data TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c65dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:13:52.159647Z",
     "start_time": "2021-05-26T13:13:23.017562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "\n",
    "# These numbers determined experimentally.\n",
    "n = 2 # Number of shards in each polygon.\n",
    "N = 20 # Total sample size in each polygon.\n",
    "\n",
    "# Export all the training data (in many pieces), with one task \n",
    "# per geometry.\n",
    "for g in range(trainingPolys.size().getInfo()):\n",
    "    geomSample = ee.FeatureCollection([])\n",
    "    for i in range(n):\n",
    "        print(i)\n",
    "        sample = arrays.sample(\n",
    "          region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
    "          scale = 30,\n",
    "          numPixels = N / n, # Size of the shard.\n",
    "          seed = i,\n",
    "          tileScale = 8\n",
    "        )\n",
    "        geomSample = geomSample.merge(sample)\n",
    "\n",
    "    desc = TRAINING_BASE + '_g' + str(g)\n",
    "\n",
    "    \n",
    "    task = ee.batch.Export.table.toCloudStorage(\n",
    "                                                collection = geomSample,\n",
    "                                                description = desc,\n",
    "                                                bucket = BUCKET,\n",
    "                                                fileNamePrefix = FOLDER + '/' + desc,\n",
    "                                                fileFormat = 'TFRecord',\n",
    "                                                selectors = BANDS + [RESPONSE], \n",
    "                                                )\n",
    "    task.start()\n",
    "    print('g : ' , g)\n",
    "    \n",
    "    \n",
    "# Monitor task progress\n",
    "# Code Extracted here:\n",
    "# https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb\n",
    "# import time \n",
    "# while task.active():\n",
    "#   print('Polling for task (id: {}).'.format(task.id))\n",
    "#   time.sleep(5)\n",
    "\t\n",
    "# print('Done!')\n",
    "\n",
    "# Export all the evaluation data.\n",
    "for g in range(evalPolys.size().getInfo()):\n",
    "    geomSample = ee.FeatureCollection([])\n",
    "    for i in range(n):\n",
    "        sample = arrays.sample(\n",
    "                              region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
    "                              scale = 30,\n",
    "                              numPixels = N / n,\n",
    "                              seed = i,\n",
    "                              tileScale = 8\n",
    "                            )\n",
    "        geomSample = geomSample.merge(sample)\n",
    "\n",
    "desc = EVAL_BASE + '_g' + str(g)\n",
    "task = ee.batch.Export.table.toCloudStorage(\n",
    "                                        collection = geomSample,\n",
    "                                        description = desc,\n",
    "                                        bucket = BUCKET,\n",
    "                                        fileNamePrefix = FOLDER + '/' + desc,\n",
    "                                        fileFormat = 'TFRecord',\n",
    "                                        selectors = BANDS + [RESPONSE]\n",
    "                                        )\n",
    "task.start()\n",
    "task.status()\n",
    "# Monitor task progress\n",
    "# Code Extracted here:\n",
    "# https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb\n",
    "import time \n",
    "while task.active():\n",
    "  print('Polling for task (id: {}).'.format(task.id))\n",
    "  time.sleep(5)\n",
    "task.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970be0a5",
   "metadata": {},
   "source": [
    "### Parse TFRecords and get back tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc45e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:24:42.673597Z",
     "start_time": "2021-05-26T13:24:42.665007Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_tfrecord(example_proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "    example_proto: a serialized Example.\n",
    "    Returns:\n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "    \"\"\"\n",
    "    return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "    \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "    Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "    Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "    Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "    \"\"\"\n",
    "    inputsList = [inputs.get(key) for key in FEATURES]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    # Convert from CHW to HWC\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "\n",
    "def get_dataset(pattern):\n",
    "    \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "    Get all the files matching the pattern, parse and convert to tuple.\n",
    "    Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "    Returns:\n",
    "    A tf.data.Dataset\n",
    "    \"\"\"\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "    dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f3a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:26:58.928654Z",
     "start_time": "2021-05-26T13:26:53.612273Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "    return dataset\n",
    "\n",
    "training = get_training_dataset()\n",
    "\n",
    "print(iter(training.take(1)).next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611bf91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T13:20:41.751014Z",
     "start_time": "2021-05-26T13:20:41.734035Z"
    }
   },
   "outputs": [],
   "source": [
    "type(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f8d9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:55:14.692313Z",
     "start_time": "2021-05-26T10:55:11.434808Z"
    }
   },
   "outputs": [],
   "source": [
    "images , labels = iter(training.take(1)).next()\n",
    "labels[0,:,:,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70b9ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:36:36.447921Z",
     "start_time": "2021-05-26T10:36:36.441244Z"
    }
   },
   "outputs": [],
   "source": [
    "images[i, :, : , 3].numpy(), images[i, :, : , 2].numpy(), images[i, :, : , 1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd9565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:46:08.481493Z",
     "start_time": "2021-05-26T10:46:08.471146Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.max(np.flip(images[i, :, : , 1:4].numpy(), axis=2), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e919f9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:48:48.725120Z",
     "start_time": "2021-05-26T10:48:48.381614Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1 )\n",
    "    plt.imshow(np.flip(images[i, :, : , 1:4].numpy(), axis=2)*10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec541d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:32:53.699099Z",
     "start_time": "2021-05-26T10:32:53.410213Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(labels[i, :, : , :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c8245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:33:14.069870Z",
     "start_time": "2021-05-26T10:33:14.066526Z"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cd2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T10:01:32.876532Z",
     "start_time": "2021-05-26T10:01:32.722367Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_eval_dataset():\n",
    "    \"\"\"Get the preprocessed evaluation dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of evaluation data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset\n",
    "\n",
    "evaluation = get_eval_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b31f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
